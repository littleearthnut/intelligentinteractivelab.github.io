<!DOCTYPE html>
<html lang="en">

<title>EEG Confuse Dataset</title>

<head>
	<meta charset="UTF-8">
	<meta http-equiv="X-UA-Compatible" content="IE=edge">
	<meta name="viewport" content="width=device-width, initial-scale=1.0">

	<!-- 引用自己的库 -->
	<link rel="stylesheet" href="../../resource/css/cite.css">
	<script src="../../resource/js/cite.js"></script>
	<link rel="shortcut icon" href="../../img/eeg-icon.svg">

	<!-- 3.6.0最新 -->
	<script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js"></script>

	<!-- bootstrap 4.6.0 -->
	<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.0/dist/css/bootstrap.min.css">
	<script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.0/dist/js/bootstrap.min.js"></script>

	<!-- tocbot 4.12.3 -->
	<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/tocbot@4.12.3/dist/tocbot.css">
	<script src="https://cdn.jsdelivr.net/npm/tocbot@4.12.3/dist/tocbot.min.js"></script>

</head>

<nav class="site-header sticky-top py-1">
	<div class="container d-flex flex-column flex-md-row justify-content-between">
		<a class="py-2" href="../../index.html" aria-label="回到主页">
			<img src="../../resource/img/eeg-icon.svg" style="display:block;width:24px;height:24px" />
			<!-- <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" stroke="currentColor"
				stroke-linecap="round" stroke-linejoin="round" stroke-width="2" class="d-block mx-auto" role="img"
				viewBox="0 0 24 24" focusable="false">
				<title>回到主页</title>
				<circle cx="12" cy="12" r="10"></circle>
				<path
					d="M14.31 8l5.74 9.94M9.69 8h11.48M7.38 12l5.74-9.94M9.69 16L3.95 6.06M14.31 16H2.83m13.79-4l-5.74 9.94">
				</path>
			</svg> -->
		</a>
		<a class="py-2 d-none d-md-inline-block" href="index.html">Home</a>
		<a class="py-2 d-none d-md-inline-block" href="readme.html">Description</a>
		<a class="py-2 d-none d-md-inline-block" href="download.html">Download</a>
	</div>
</nav>

<body style="font-family: '微软雅黑';">


	<div class="container">
		<div class="row">
			<div class="col-2">

			</div>
			<div class="col-8 js-toc-content">
				<img src="./resource/img/confuse-experiment.png" />
				<h2>
					abstract
				</h2>


				We present a database for research on affect, personality traits and mood by means of
				neuro-physiological signals. Different to other databases, we elicited affect using both short and long
				videos in two configurations, one with individual viewers and one with groups of viewers. The database
				allows the multimodal study of the affective responses of individuals in relation to their personality
				and mood, and the analysis of how these responses are affected by (i) the individual/group
				configuration, and (ii) the duration of the videos (short vs long). The data is collected in two
				experimental settings. In the first one, 40 participants watched 16 short emotional videos while they
				were alone. In the second one, the same participants watched 4 long videos, some of them alone and the
				rest in groups. In both settings, the participants' signals, namely, Electroencephalogram (EEG),
				Electrocardiogram (ECG), and Galvanic Skin Response (GSR), were recorded using wearable sensors.
				Frontal, full-body and depth videos were also recorded. Participants have been profiled for personality
				using the Big-five personality traits, and for mood with the baseline Positive Affect and Negative
				Affect Schedules. Participants emotions have been annotated with both, self-assessment of affective
				levels (valence, arousal, control, familiarity, like/dislike, and selection of basic emotion) felt by
				the participants during the first experiment, and external-assessment of participants' levels of valence
				and arousal for both experiments. We present a detailed correlation analysis that includes correlations
				between self-assessment and external-assessment of affect, between valence and arousal elicited by short
				and long videos on individuals and groups, as well as, between personality, mood, social context, and
				affect dimensions. We also present baseline methods and results for single-trial classification of
				valence and arousal, and for single-trial classification of personality traits, mood and social context
				(alone vs group), using EEG, GSR and ECG and fusion of modalities for both experiments.

				The database has been made publicly available. The dataset was first presented in the following paper:

				"AMIGOS: A Dataset for Affect, Personality and Mood Research on Individuals and Groups (PDF)", J.A.
				Miranda-Correa, M.K. Abadi, N. Sebe, and I. Patras, IEEE Transactions on Affective Computing, 2018.
				<h2>how to use</h2>
				If you are interested in using this dataset, you will have to print, sign and scan an EULA (End User
				License Agreement) and upload it via the dataset request form. We will then supply you with a username
				and password to download the data. Please head on over to the downloads page for more details.

				Also, please consult the dataset description page for a complete explanation of the dataset.

				<h2>credits</h2>
				First and foremost we'd like to thank the 40 participants in this study for having the patience and
				goodwill to let us record their data.
				This dataset was collected by:

				Juan Abdon Miranda Correa, Queen Mary University of London, United Kingdom
				Mojtaba Khomami Abadi, University of Trento, Italy
				All this work has been guided by our supervisors:

				Dr. Ioannis Patras, Queen Mary University of London, United Kingdom
				Dr. Nicu Sebe, University of Trento, Italy
				Finally, we'd like to thank our funding bodies:

				Consejo Nacional de Ciencia y Tecnología, Mexico. Scholarship number 359169.

			</div>
			<div class="col-mb-12 col-2 kit-hidden-tb post-toc-content">
				<div id="toc-container" class="post-toc">
					<div class="toc"></div>
				</div>
			</div>
		</div>
	</div>


	<hr>
	<footer class="blockquote text-center">
		<dir class="row">
			<div class="col-md-12 ">
				<small class="d-block mb-3 text-muted">Intelligent Interaction Laboratory @ NWPU</small>

				<small class="d-block mb-3 text-muted">All Rights Reserved © 2019-<div id="year"
						style="display: inline-block">LastYear</div></small>
			</div>
		</dir>
	</footer>
</body>
<script language="javascript" type="text/javascript">
	add_head_id();

	tocify();
	footer_year();
</script>

</html>